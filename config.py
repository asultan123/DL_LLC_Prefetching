BATCH_SIZE: int = 1024
GENERATE_BATCH_SIZE: int = 2048
DIFFS_DEFAULT_WINDOW: int = 8
SEQ_LEN: int = 32
N_LAYERS: int = 2
HIDDEN_DIM: int = 256
MAX_CLIP: int = 50
GPU_MEM_SIZE_BYTES: int = 8 * (2 ** 30)
GPU_MEM_SIZE_MARGIN_BYTES: int = 1 * (2 ** 30)
TRANSFORMER_ENCODER_NTOKENS :int = 4 # embedding dimension
TRANSFORMER_ENCODER_EMSIZE :int = 64 # embedding dimension
TRANSFORMER_ENCODER_NHID :int = 64 # the dimension of the feedforward network model in nn.TransformerEncoder
TRANSFORMER_ENCODER_NLAYERS :int = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder
TRANSFORMER_ENCODER_NHEAD :int = 4 # the number of heads in the multiheadattention models
TRANSFORMER_ENCODER_DROPOUT :int = 0.2 # the dropout value
LLC_LINE_SIZE = 64